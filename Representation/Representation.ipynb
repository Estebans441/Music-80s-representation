{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59368fa7",
   "metadata": {},
   "source": [
    "# Representacion no estructurada de canciones de los 80s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202756a9",
   "metadata": {},
   "source": [
    "## Importacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install scikit-learn matplotlib pandas seaborn nltk numpy spacy gensim==3.8.3 pyLDAvis==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099c92d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancion</th>\n",
       "      <th>Artista</th>\n",
       "      <th>Letra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A esa</td>\n",
       "      <td>Pimpinela</td>\n",
       "      <td>L VEN AQUI, QUIERO DECIRTE ALGO...\\n\\nA esa, q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A quién le importa</td>\n",
       "      <td>Alaska y Dinarama</td>\n",
       "      <td>La gente me señala\\n\\nme apuntan con el dedo\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amante Bandido</td>\n",
       "      <td>Miguel Bosé</td>\n",
       "      <td>Yo seré el viento que va\\n\\nnavegare por tu os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amor Eterno</td>\n",
       "      <td>Rocío Dúrcal</td>\n",
       "      <td>Tu eres la tristeza de mis ojos \\nque lloran e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ausencia</td>\n",
       "      <td>Héctor Lavoe</td>\n",
       "      <td>Ha terminado otro capítulo en mi vida \\nLa muj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Cancion            Artista  \\\n",
       "0               A esa          Pimpinela   \n",
       "1  A quién le importa  Alaska y Dinarama   \n",
       "2      Amante Bandido        Miguel Bosé   \n",
       "3         Amor Eterno       Rocío Dúrcal   \n",
       "4            Ausencia       Héctor Lavoe   \n",
       "\n",
       "                                               Letra  \n",
       "0  L VEN AQUI, QUIERO DECIRTE ALGO...\\n\\nA esa, q...  \n",
       "1  La gente me señala\\n\\nme apuntan con el dedo\\n...  \n",
       "2  Yo seré el viento que va\\n\\nnavegare por tu os...  \n",
       "3  Tu eres la tristeza de mis ojos \\nque lloran e...  \n",
       "4  Ha terminado otro capítulo en mi vida \\nLa muj...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importacion de las letras desde el directorio de letras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear dataframe con las letras: Cancion, Letra y Artista\n",
    "canciones = []\n",
    "for file in os.listdir('letras'):\n",
    "    with open(f'letras/{file}', encoding='utf-8') as f:\n",
    "        cancion = ' '.join(file.split('.')[0:-1]).strip()\n",
    "        nombre = ' '.join(cancion.split('-')[0:-1]).strip()\n",
    "        artista = cancion.split('-')[-1].strip()\n",
    "        letras = f.read()\n",
    "        canciones.append([nombre, artista, letras])\n",
    "\n",
    "canciones = pd.DataFrame(canciones, columns=['Cancion', 'Artista', 'Letra'])\n",
    "\n",
    "canciones.to_csv('canciones.csv', index=False)\n",
    "\n",
    "canciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bca839",
   "metadata": {},
   "source": [
    "## Representacion TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f7c96",
   "metadata": {},
   "source": [
    "### Entendimiento y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b227835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras = canciones['Letra'].values.tolist()\n",
    "len(letras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222ed60",
   "metadata": {},
   "source": [
    "Importacion de la libreria de stopwords y definicion de una funcion para filtrar las canciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7369eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "misstop=stopwords.words('spanish')+[\"á\",\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70725aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrado(texto):\n",
    "    filtrados=[word for word in texto if word not in misstop]\n",
    "    return(filtrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7292feb",
   "metadata": {},
   "source": [
    "La limpieza incluira:\n",
    "\n",
    "**a)** pasar a minúsculas\n",
    "\n",
    "**b)** retirar páginas web\n",
    "\n",
    "**c)** quitar saltos de línea y tabuladores\n",
    "\n",
    "**d)** retirar stopwords\n",
    "\n",
    "**e)** retirar menciones\n",
    "\n",
    "**f)** unir todo de nuevo\n",
    "\n",
    "**g)** eliminar letras solas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192e4237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "filtradito=[]\n",
    "# Eliminar menciones y páginas web\n",
    "for i in range(len(letras)):\n",
    "    letras[i] = re.sub(\"\\\"\",\" \",letras[i])\n",
    "    letras[i] = re.sub (\"\\n|\\t\",\" \",letras[i])\n",
    "    letras[i]=letras[i].lower()\n",
    "    letras[i] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', letras[i])\n",
    "    letras[i] = re.sub(r'\\xad+', ' ', letras[i], flags=re.I)\n",
    "    breve=nltk.tokenize.word_tokenize(letras[i],language=\"spanish\")\n",
    "    tempfilt=filtrado(breve)\n",
    "    filtradito.append(tempfilt)\n",
    "    \n",
    "unidito=[]\n",
    "for element in filtradito:\n",
    "    unidito.append(\" \".join(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f248c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l ven aqui , quiero decirte ... , aparta , roba tiempo , alma cuerpo , ve dile ... quieres ? venga , valor , muestre cara hable frente si quiere amor ... ? , contigo va vestida princesa , , hace preguntas siempre está¡ dispuesta , , vete dile ... ? venga ... ? doy lugar ... quieres probar ? recoja mesa , lave ropa todas miserias ... quieres demostrar ? venga , juegue ... vas conseguir ? quiero ver si capaz darte cosas di ... , ... vete dile , venga ... , pone tan mal capaz hacerme volver vivir ilusiones perdidas . , hace hablar debo cosas hace tiempo das ... , puede costar hacerte feliz hora día ? , toca vivir ninguna tristeza , alegrí a. vete dile .. ? venga ... ? doy lugar ... quieres probar ? recoja mesa , lave ropa todas miserias ... quieres demostrar ? venga , juegue ... vas conseguir ? quiero ver si capaz darte cosas di ... venga ... ... doy lugar ... quieres probar ... recoja mesa lave ropa todas miserias quieres demostrar ... venga juegue ... vas conseguir ... quiero ver si capaz darte cosas to di ... , ... vete dile , venga ...'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidito[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8464f0",
   "metadata": {},
   "source": [
    "### Determinacion de Topicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598af88b",
   "metadata": {},
   "source": [
    "Importacion de librerias para topicos de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee177f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae2733",
   "metadata": {},
   "source": [
    "Estraccion de topicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79217b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7507af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "si quiero voy amor sé vos vez noche siempre nadie\n",
      "Topic 1:\n",
      "vida pido why toda asi así amor ahora prefiero nunca\n",
      "Topic 2:\n",
      "oh bajo parte playa calienta cerca aquí luna sol busco\n",
      "Topic 3:\n",
      "desaparecer ayer amor muralla divide mirando parado vuelve viene realidad\n",
      "Topic 4:\n",
      "ayudarla sacarla puedo pozo aca escucho abajo mas mirarla calla\n"
     ]
    }
   ],
   "source": [
    "vectores=TfidfVectorizer(max_df=0.9,min_df=2,max_features=1000)\n",
    "tfslimpio=vectores.fit_transform(unidito)\n",
    "nombreslimpio=vectores.get_feature_names_out()\n",
    "nmflimpio = NMF(n_components=5, random_state=1, l1_ratio=.5, init='nndsvd').fit(tfslimpio)\n",
    "no_top_words=10\n",
    "display_topics(nmflimpio, nombreslimpio, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246cfc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombreslimpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480d20",
   "metadata": {},
   "source": [
    "Utilizacion de conteos para LDA (Latent Dirilchet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a06a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "vida mundo ay solo toda tan así oh si llorar\n",
      "Topic 1:\n",
      "amor eu debajo um rock não ayer desaparecer corazón dia\n",
      "Topic 2:\n",
      "oh nadie vete bis puede verás jamás hombre luna lleva\n",
      "Topic 3:\n",
      "na quiero amor noches vida cinco pido luna noche vez\n",
      "Topic 4:\n",
      "amo je lluvia si nadie fríos besos días gota non\n",
      "Topic 5:\n",
      "importa asi si pasa siempre nunca amor ahora manos primavera\n",
      "Topic 6:\n",
      "si amor sé ahora quiero puedo nunca siempre vida gente\n",
      "Topic 7:\n",
      "si ven mas quiero voy nene van solo amor ser\n"
     ]
    }
   ],
   "source": [
    "paralda = CountVectorizer(max_df=0.9, min_df=2, max_features=1000)\n",
    "tflda=paralda.fit_transform(unidito)\n",
    "nombreslda=paralda.get_feature_names_out()\n",
    "lda = LatentDirichletAllocation(n_components=8, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tflda)\n",
    "id_topico=lda.fit_transform(tflda)\n",
    "display_topics(lda,nombreslda,no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25596111",
   "metadata": {},
   "source": [
    "Pertenencia de cada documento a su topico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90fff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = nmflimpio.transform(tfslimpio)\n",
    "topic_most_pr=[]\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr.append(doc_topic[n].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e1929a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancion</th>\n",
       "      <th>nmf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A esa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A quién le importa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amante Bandido</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amor Eterno</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ausencia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Y cómo es él</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Yo No Te Pido La Luna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Yo te avisé</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Ámame en cámara lenta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Él Me Mintió</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cancion  nmf\n",
       "0                    A esa    0\n",
       "1       A quién le importa    1\n",
       "2           Amante Bandido    0\n",
       "3              Amor Eterno    0\n",
       "4                 Ausencia    0\n",
       "..                     ...  ...\n",
       "100           Y cómo es él    1\n",
       "101  Yo No Te Pido La Luna    1\n",
       "102            Yo te avisé    0\n",
       "103  Ámame en cámara lenta    1\n",
       "104           Él Me Mintió    0\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "canciones[\"nmf\"]=topic_most_pr\n",
    "ver_cerveza=canciones[[\"Cancion\",\"nmf\"]]\n",
    "display(ver_cerveza)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc352392",
   "metadata": {},
   "source": [
    "### Visualizacion de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbdc9f",
   "metadata": {},
   "source": [
    "Gensim y pyLDAvis para ver los resultados de LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42f6431",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcorpora\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_preprocess\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\matutils.py:1034\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\Trabajos U\\FAM\\Music-80s-representation\\.venv\\Lib\\site-packages\\gensim\\_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b7591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
      "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"es\")\n",
    "nlp=spacy.load(\"es_core_news_sm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
